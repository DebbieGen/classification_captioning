# 🧠 IBM Project: Image Classification and Captioning

---

## 📌 Overview

This IBM project combines **image classification** and **image captioning** into a unified deep learning pipeline using CNNs and Transformer models. The model takes an image as input, predicts its category, and generates a descriptive caption — showcasing the power of **vision-language modeling**.

---

## 🚀 Features

- Image classification using pre-trained VGG16
- Caption generation with BLIP Transformer from HuggingFace
- End-to-end training in a Jupyter Notebook
- Accuracy and BLEU score evaluation
- Visual examples of predictions and captions

---

## 📁 Files

- IBM_Project_Classification_and_Captioning.ipynb: Main notebook with full pipeline

- aircraft_damage_dataset_v1: Aircraft images labeled either as 'dent' or 'crack' split into train, valid, and test sets. Dataset is taken from the Roboflow Aircraft Dataset (https://universe.roboflow.com/youssef-donia-fhktl/aircraft-damage-detection-1j9qk) Provided by a Roboflow user, License: CC BY 4.

## 📚 Dependencies

Key libraries used:

- TensorFlow / Keras

- HuggingFace Transformers (BLIP)

- Pillow

- Matplotlib, NumPy

- Jupyter

---

## 🧪 Usage
To run the project:

jupyter notebook IBM_Project_Classification_and_Captioning.ipynb

Then follow the cells in order to:

- Load and preprocess image data

- Train the classification model

- Generate captions

- Evaluate predictions

---

## 📄 License

This project is licensed under the MIT License.
